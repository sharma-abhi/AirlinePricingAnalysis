---
title: "Assignment 7"
author: "Abhijeet Sharma, Deepend Mehta, Akshay Raje, Afan Ahmad Khan"
date: "Saturday, March 19, 2016"
output: pdf_document
---
### INTRODUCTION
The program builds a Flight Prediction model which trains on history data and predicts on test dataset. The purpose of the program is to propose two-hop routes that minimize the chance of missed connections for a future date.
There is only 1 Model which is trained on all of the History Data and predicted on the test data.
The model is built using Apache Spark framework. The Classifier used is Random Forest.
The Classifier's output predictions is found in Output/TestPredictions/test-predictions in the format: "year, month, day, originAirport ,destinationAirport, originFlightNum, destinationFlightNum, duration and predicted missed connections".

Fine print: 
1. We Provide code that can run pseudo-distributed hadoop/spark as well as on AWS EMR. 
2. We have provided a Confusion Matrix evaluating the prediction Results.
3. We also calculated error rate as a measure of accuracy of our model where 
error rate = % of on-time flights misclassified as delayed + % of delayed flights misclassified as on-time.
4. We have included a MakeFile that executes the piepline and produces this Report. 
5. This one page report documents our implementation and describes our results. The report is 
automatically constructed as part of running the pipeline.
6. We have submitted a tar.gz file which unpacks into a directory name "Sharma_Mehta_Raje_Khan_A7". The directory contains a README file that explains how to build and run our code.

\newpage

### IMPLEMENTATION
1. The Whole Program Pipeline is divided into four parts, 
a MR Job for cleaning Train Data, 
a MR Job for cleaning Test Data,
a Spark job for building a Prediction Model for Missed Connections
a R program for running the Validation data on the Predicted Dataset
  We built a Random Forest Model and trained in with approx **25 million Records** and tested it with approx **181000**  Records.
The Model is trained on the History Data and predicted on the test data. This test data is the data filtered out after reading records from the Requested data.
We have implemented a specific Seed(=42) for our Random Forest Model for reproducing results.
2. In the Map Reduce Jobs, The Mapper calls the map method with "Carrier Code + Origin/Destination" as Key. The record is checked for sanity tests and Feature Columns are sent to the Reducer as Values.
Note: The choice of Carrier Code and Origin/Destination as key is done for computing missed connections.It has no impact on the Prediction Model.
3. The reducer does an equi-join on intermmediate airports for a two-hop route.It also calculates the number of missed connections for training data and extracts the required features for the predication model. Rows from the request file are used to filter on the test data.
4. The output Training and Test files are consolidated and sent to the AWS Spark program as inputs.
5. The Spark program builds a random forest model on the training set and predicts on the test data.It outputs a file containing records in the format: [year, month, day, originAirport ,destinationAirport, originFlightNum, destinationFlightNum, duration and predicted missed connections].
6. The R script reads the Spark output file and computes the flight with the minimum duration. It also calculates the accuracy of the prediction model with the help of the validation file.
7. Make file is created to automate the pipeline in both local machine and AWS EMR clusters.

\newpage

### DIRECTORY STRUCTURE
```{}
* has to be set by user manually before run
+ is created by the Program during execution

|Sharma_Mehta_Raje_Khan_A7
|README.txt                         (Description of the Submission)
|MakeFile                           (Makefile for the project)
|Assignment7_Report.pdf             (PDF Report of the project results)
|Assignment7_Report.Rmd             (Rmd file for the Report)
|PreProcessFlight.java              (Hadoop MR Driver Java file)
|PreProcessMapper.java              (Hadoop MR Mapper Java file)
|PreProcessMapper.java              (Hadoop MR Driver Java file)
|CSVParser.java                     (Open Source Implementation For parsing of input records)
|CSVReaderNullFieldIndicator.java   (Helper File for CSVParser.java)
|commons-lang3-3.4.jar              (Helper File for CSVParser.java)
|clusterWaitingCheck.sh             (Shell script which waits for cluster to complete a step)
|sparkConfig.json                   (Configuration File for Spark in JSON)
|SparkModel
|SparkModel.scala               (Spark Machine Learning Model Creation Scala file)
|build.sbt                      (sbt File for building scala JAR package)
|input*
|a7history|(36 csv.gz files)*
|a7test|04redacted.csv.gz*
|a7validate|04missed.csv.gz*
|a7request|04req10k.csv.gz*
|output+
|a7history+
|a7test+
|TestPredictions
|FeatureImportance
```            

Install the required R Packages
```{r, eval=FALSE}
install.packages("rmarkdown")
install.packages("ggplot2")
install.packages("e1071")
install.packages("caret")
install.packages("plyr")
install.packages("R.utils")
```
\newpage

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Load required packages
library(plyr)
library(caret)
library(R.utils)
args <- commandArgs(trailingOnly = TRUE)
# Reads the first argument as loads it into variable - filename
input.dir <- args[1]
#input.dir <- "output/TestPredictions"
filename <- "final-predictions"
predictions.df <- read.csv(file=paste(input.dir, filename, sep="/"), sep=",", 
                           header=FALSE, stringsAsFactors = FALSE)
predictions.df$V1 <- as.integer(gsub("\\[", "", predictions.df$V1))
predictions.df$V9 <- as.integer(gsub("]", "", predictions.df$V9))
predictions.df$key <- paste(predictions.df$V1,predictions.df$V2,predictions.df$V3,predictions.df$V4,predictions.df$V5, sep="_")
predictions.df <- predictions.df[,-c(1,2,3,4,5)]
predictions.df <- predictions.df[order(predictions.df$key),]
names(predictions.df) <- c("Flight1", "Flight2", "Duration", "Missed", "Key")
predictions.df$FinalDuration <- predictions.df$Duration
predictions.df[predictions.df$Missed == 1, ]$FinalDuration <- predictions.df[predictions.df$Missed == 1, ]$FinalDuration + 100
ans.df <- ddply(predictions.df, c("Key"), function(df){
  df[df$FinalDuration==min(df$FinalDuration), ]
})
filtered.ans.df <- data.frame(ans.df$Key, ans.df$Flight1, ans.df$Flight2, ans.df$FinalDuration)
write.table(filtered.ans.df, file="final-response.csv", row.names = FALSE, col.names = FALSE, quote = FALSE, sep=",")
```
### Confusion Matrix
```{r, echo=FALSE, warning=FALSE, message=FALSE}
valid.dir <- args[2]
#valid.dir <- "input/a7validate"
valid_file <- "04missed.csv.gz"
gunzip(paste(valid.dir, valid_file, sep="/"), ext="gz", remove=FALSE, overwrite=TRUE)
valid_unzipped_file <- "04missed.csv"
val <- read.csv(file=paste(valid.dir, valid_unzipped_file, sep="/"), header=FALSE)
val$key <- paste(val$V1,val$V2,val$V3,val$V4,val$V5,val$V6,val$V7, sep="_")
val$missed <- 1
val <- val[,-c(1,2,3,4,5,6,7)]
names(val) <- c("Key","ActMissed")
val <- unique(val)

pred <- data.frame(predictions.df$Key, predictions.df$Flight1, predictions.df$Flight2, predictions.df$Missed)
names(pred) <- c("Key", "Flight1", "Flight2", "PredMissed")
pred$key <- paste(pred$Key, pred$Flight1, pred$Flight2, sep="_")
pred <- pred[,-c(1,2,3)]
names(pred) <- c("PredMissed","Key")

fin <- merge(x = pred, y = val, all.x = TRUE)
fin[is.na(fin$ActMissed),]$ActMissed <- 0
write.table(fin, file="evaluation.csv", row.names = FALSE, col.names = FALSE, quote = FALSE, sep=",")


fin$PredMissed <- factor(fin$PredMissed, levels=0:1, labels=c("Not-Missed", "Missed"))
fin$ActMissed <- factor(fin$ActMissed, levels=0:1, labels=c("Not-Missed", "Missed"))

res <- confusionMatrix(fin$PredMissed,fin$ActMissed, dnn=c("Predicted", "Actual"), positive="Not-Missed")
res
```

\newpage

### Feature Importances (in decreasing order of importance)
```
Layover (Minutes)                          -> 0.7910760348376943
CRS Time (Hour)                            -> 0.17667292405685459
Popular Origin (1:Popular,0:Not Popular)   -> 0.01225633896699857
Day of Week (in number)                    -> 0.011876846115361201
Month                                      -> 0.005054899900618705
DistanceGroup                              -> 0.003062956122472584
```
```{r, echo=FALSE, warning=FALSE, message=FALSE}
require(ggplot2)
features <- c("popularOrigin", "layover", "dayOfWeek", "month", "crsTime", "distanceGroup")
featureImportances <- c(0.01225633896699857, 0.7910760348376943, 0.011876846115361201, 0.005054899900618705, 0.17667292405685459, 0.003062956122472584)
df <- data.frame(features, featureImportances)
df$Importance <- round(df$featureImportances,3)
df <- df[, -c(1)]
df <- df[order(-df$Importance),]
baseplot <- ggplot(data=df, aes(factor(features, level=unique(features)), Importance, label=Importance))
baseplot +
  ggtitle("Feature importance plot for the model") +
  xlab("Features") + 
  ylab("Importance (higher the better)") + 
  theme(plot.title = element_text(size=13, face = "bold")) +
  theme(axis.title = element_text(face = "bold")) +
  theme(axis.text = element_text(size=9)) +
  geom_bar(stat="identity", width=0.5, fill="cadetblue3") + 
  geom_text(size=4, hjust=0.5, vjust=-0.5) + 
  scale_y_continuous() 
```  

\newpage

### Timings (All times are in minutes)
```
1. Local Machine
  1.1 Preprocessing Train and Test Data     18 minutes  
  1.2 Spark ML                              20 minutes

2. AWS Cluster 3 CORE m3.xlarge machines
  2.1 Preprocessing Train and Test Data     10 minutes
  2.2 Spark ML                              7 minutes
```
* AWS timings might vary depending on load.
** AWS timings include only step execution times.

### SYSTEM SPECIFICATION & REQUIREMENTS:
```
1. Ubuntu 14.04 64-bit, 8GB RAM
2. Java 1.7.0_79
3. Apache Hadoop v.2.6.3 (http://www-us.apache.org/dist/hadoop/common/hadoop-2.6.3/hadoop-2.6.3.tar.gz)
4. Scala v.2.10.6 (http://www.scala-lang.org/download/2.10.6.html)
4. sbt 
Linux: http://www.scala-sbt.org/release/docs/Installing-sbt-on-Linux.html
Mac: http://www.scala-sbt.org/release/docs/Installing-sbt-on-Mac.html
5. Apache Spark v.1.6.0 (http://www-eu.apache.org/dist/spark/spark-1.6.0/spark-1.6.0-bin-hadoop2.6.tgz)
6. Pandoc (https://github.com/jgm/pandoc/releases/tag/1.16.0.2)
7. R Packages:
  7.1 ggplot2
  7.2 rmarkdown
  7.3 e1071
  7.4 caret
  7.5 dplyr
  7.6 R.utils
```
\newpage

### Design Justifications:
1. Implement the sanity function and feature extraction logic in Spark itself instead of Hadoop jobs.
  -> "We weren't able to do this due to unfamiliarity with Scala/Spark and lack of time.Hopefully in the future, we will be incorporating it."
2. Implement Cross-Validation Techniques
  -> "This assignment simulates a production scenario where cross-validation and data exploration would have already been done with small samples of data."
3. Use <XYZ> Classifier
  -> "Due to lack of time, we only tested our pipeline with Gradient Boosted Trees and Random Forest.RF had higher accuracy than GBT although the difference in accuracy was minimal."
4. Implement Weka, R... instead of Spark
  -> "We didn't opt for Weka or R since they weren't built for handling huge datasets.To make it work, we would have had to either a) use workaounds like calling different processes, b) limit the scope of our model per year or per quarter.We believed implementing either of these choices would be right when Apache Spark can handle huge datasets and provides DataaFrames and Machine Learning libraries.We hence opted to build our Prediction model in Apache Spark.Instead of building multiple models, we can build one single effective model.Also, building in spark and deploying in AWS makes our program scalable in the future"
5. Sampling of training data 
  -> The history data was highly skewed in favour of not missed connections. Only 15% of training data is missed. Due to this skewness our model would be highly susceptible to overfit on not-missed data. To resolve this we have done exploratory data analysis in R and confirmed that taking 20% of non-missed data from the training dataset would create a more balanced model. Hence we have trained the model on 20% of non-missed data and 100% of missed data which helped create a more balanced model.
